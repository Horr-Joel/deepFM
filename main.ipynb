{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=UTF-8\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import config\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from DataReader import FeatureDictionary, DataParser\n",
    "from DeepFM import DeepFM\n",
    "\n",
    "# 419858\n",
    "def _load_data():\n",
    "\n",
    "#     dfTrain = pd.read_csv(config.TRAIN_FILE)\n",
    "#     dfTest = pd.read_csv(config.TEST_FILE)\n",
    "    dfTrain = pd.read_csv('../../Tencent Data/train_value2index.csv')\n",
    "    dfTest = pd.read_csv('../../Tencent Data/test_value2index.csv')\n",
    "    dfTrain.loc[dfTrain['label'] == -1, 'label'] = 0\n",
    "\n",
    "#     delcol = ['ct','os', 'topic1', 'topic2', 'topic3', 'kw1', 'kw2', 'kw3',\n",
    "#     'interest1', 'interest2', 'interest3', 'interest4', 'interest5', \n",
    "#     'marriageStatus', 'appIdAction', 'appIdInstall']\n",
    "#     for each in delcol:\n",
    "#         del dfTrain[each]\n",
    "#         del dfTest[each]\n",
    "        \n",
    "#      加入交叉特征\n",
    "#     cross_feat = pd.read_csv('../data_cross_feat.csv')\n",
    "#     dfTrain = pd.concat([dfTrain, cross_feat[:8798814]])\n",
    "#     dfTest = pd.concat([dfTest, cross_feat[8798814:]])\n",
    "#     del cross_feat\n",
    "#     gc.collect()\n",
    "    \n",
    "    dfTrain.fillna(419859,inplace=True)\n",
    "    dfTest.fillna(419859,inplace=True)\n",
    "    cols = [c for c in dfTrain.columns if c not in [\"uid\", \"label\"]]\n",
    "    cols = [c for c in cols if (not c in config.IGNORE_COLS)]\n",
    "\n",
    "    X_train = dfTrain[cols].values\n",
    "    y_train = dfTrain[\"label\"].values\n",
    "\n",
    "\n",
    "    return dfTrain, dfTest, X_train, y_train\n",
    "\n",
    "\n",
    "#def _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params):\n",
    "def _run_base_model_dfm(Xi_train ,Xv_train, y_train, Xi_test, Xv_test, folds, dfm_params):\n",
    "#     fd = FeatureDictionary(dfTrain=dfTrain, dfTest=dfTest,\n",
    "#                            numeric_cols=config.NUMERIC_COLS,\n",
    "#                            #-------------------增加多值特征列\n",
    "#                            multivalued_cols=config.MULTIVALUED_COLS,\n",
    "                           \n",
    "#                            ignore_cols=config.IGNORE_COLS)\n",
    "\n",
    "#     data_parser = DataParser(feat_dict=fd)\n",
    "\n",
    "#     Xi_train, Xv_train, y_train = data_parser.parse(df=dfTrain, has_label=True)\n",
    "\n",
    "#     Xi_test, Xv_test, res_test = data_parser.parse(df=dfTest)\n",
    "    \n",
    "#     dfm_params[\"feature_size\"] = fd.feat_dim\n",
    "    dfm_params[\"feature_size\"] = 419859\n",
    "    dfm_params[\"field_size\"] = 31\n",
    "    \n",
    "    y_train = dfTrain[\"label\"].values.tolist()\n",
    "    del dfTrain['label']#,dfTrain['uid']\n",
    "    \n",
    "    Xi_train = np.array(dfTrain).tolist()\n",
    "    Xi_train_ = []\n",
    "    for row in Xi_train:\n",
    "        a = []\n",
    "        for each in row:\n",
    "            if isinstance(each,int):\n",
    "                a.append(each)\n",
    "            elif isinstance(each,float):\n",
    "                a.append(int(each))\n",
    "            elif isinstance(each,str):\n",
    "                a.append(each.split())\n",
    "            else:\n",
    "                print each\n",
    "        Xi_train_.append(a)\n",
    "    Xi_train = Xi_train_\n",
    "    del Xi_train_\n",
    "    \n",
    "    \n",
    "    Xv_train = np.ones([len(Xi_train),len(Xi_train[0])])\n",
    "    \n",
    "    test1 = pd.read_csv('../../Tencent Data/test1.csv')\n",
    "    res_test = test1[['aid','uid']]\n",
    "    del test1\n",
    "    Xi_test = np.array(dfTest).tolist()\n",
    "    Xi_test_ = []\n",
    "    for row in Xi_test:\n",
    "        a = []\n",
    "        for each in row:\n",
    "            if isinstance(each,int):\n",
    "                a.append(each)\n",
    "            elif isinstance(each,float):\n",
    "                a.append(int(each))\n",
    "            elif isinstance(each,str):\n",
    "                a.append(each.split())\n",
    "            else:\n",
    "                print each\n",
    "        Xi_test_.append(a)\n",
    "    Xi_test = Xi_test_\n",
    "    del Xi_test_\n",
    "    Xv_test = np.ones([len(Xi_test),len(Xi_test[0])])\n",
    "    \n",
    "\n",
    "    \n",
    "    y_train_meta = np.zeros((dfTrain.shape[0], 1), dtype=float)\n",
    "\n",
    "    y_test_meta = np.zeros((dfTest.shape[0], 1), dtype=float)\n",
    "\n",
    "    _get = lambda x, l: [x[i] for i in l]\n",
    "\n",
    "    auc_results_cv = np.zeros(len(folds), dtype=float)\n",
    "\n",
    "    auc_results_epoch_train = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "\n",
    "    auc_results_epoch_valid = np.zeros((len(folds), dfm_params[\"epoch\"]), dtype=float)\n",
    "\n",
    "    for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "        Xi_train_, Xv_train_, y_train_ = _get(Xi_train, train_idx), _get(Xv_train, train_idx), _get(y_train, train_idx)\n",
    "        Xi_valid_, Xv_valid_, y_valid_ = _get(Xi_train, valid_idx), _get(Xv_train, valid_idx), _get(y_train, valid_idx)\n",
    "\n",
    "        dfm = DeepFM(**dfm_params)\n",
    "\n",
    "        dfm.fit(Xi_train_, Xv_train_, y_train_, Xi_valid_, Xv_valid_, y_valid_)\n",
    "\n",
    "        y_train_meta[valid_idx,0] = dfm.predict(Xi_valid_, Xv_valid_)\n",
    "\n",
    "        y_test_meta[:,0] += dfm.predict(Xi_test, Xv_test)\n",
    "\n",
    "        auc_results_cv[i] = roc_auc_score(y_valid_, y_train_meta[valid_idx])\n",
    "        auc_results_epoch_train[i] = dfm.train_result\n",
    "        auc_results_epoch_valid[i] = dfm.valid_result\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    y_test_meta /= float(len(folds))\n",
    "\n",
    "    # save result\n",
    "    if dfm_params[\"use_fm\"] and dfm_params[\"use_deep\"]:\n",
    "        clf_str = \"DeepFM\"\n",
    "    elif dfm_params[\"use_fm\"]:\n",
    "        clf_str = \"FM\"\n",
    "    elif dfm_params[\"use_deep\"]:\n",
    "        clf_str = \"DNN\"\n",
    "    print(\"%s: %.5f (%.5f)\"%(clf_str, auc_results_cv.mean(), auc_results_cv.std()))\n",
    "    filename = \"%s_Mean%.5f_Std%.5f.csv\"%(clf_str, auc_results_cv.mean(), auc_results_cv.std())\n",
    "    _make_submission(res_test, y_test_meta, filename)\n",
    "\n",
    "    _plot_fig(auc_results_epoch_train, auc_results_epoch_valid, clf_str)\n",
    "    \n",
    "    return y_train_meta, y_test_meta\n",
    "\n",
    "\n",
    "def _make_submission(res, y_pred, filename=\"submission.csv\"):\n",
    "    res['score'] = y_pred.flatten()\n",
    "    save_path = os.path.join(config.SUB_DIR, filename)\n",
    "    res.to_csv(save_path, index=False, float_format=\"%.6f\")\n",
    "    os.system('zip %s.zip %s' % (save_path, save_path))\n",
    "\n",
    "def _plot_fig(train_results, valid_results, model_name):\n",
    "    colors = [\"red\", \"blue\", \"green\"]\n",
    "    xs = np.arange(1, train_results.shape[1]+1)\n",
    "    plt.figure()\n",
    "    legends = []\n",
    "    for i in range(train_results.shape[0]):\n",
    "        plt.plot(xs, train_results[i], color=colors[i], linestyle=\"solid\", marker=\"o\")\n",
    "        plt.plot(xs, valid_results[i], color=colors[i], linestyle=\"dashed\", marker=\"o\")\n",
    "        legends.append(\"train-%d\"%(i+1))\n",
    "        legends.append(\"valid-%d\"%(i+1))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.title(\"%s\"%model_name)\n",
    "    plt.legend(legends)\n",
    "    T = int(time.time())\n",
    "    plt.savefig(\"./fig/%s_%d.png\"%(model_name,T))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dfTrain, dfTest, X_train, y_train = _load_data()\n",
    "\n",
    "# folds\n",
    "folds = list(StratifiedKFold(n_splits=config.NUM_SPLITS, shuffle=True,\n",
    "                             random_state=config.RANDOM_SEED).split(X_train, y_train))\n",
    "del X_train,y_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 8,\n",
    "    \"dropout_fm\": [1.0, 1.0],\n",
    "    \"deep_layers\": [100, 100],\n",
    "    \"dropout_deep\": [0.9, 0.9, 0.9],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 15,\n",
    "    \"batch_size\": 2048,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    #\"eval_metric\": gini_norm,\n",
    "    \"random_seed\": config.RANDOM_SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DeepFM Model ------------------\n",
    "y_train_dfm, y_test_dfm = _run_base_model_dfm(dfTrain, dfTest, folds, dfm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ FM Model ------------------\n",
    "fm_params = dfm_params.copy()\n",
    "fm_params[\"use_deep\"] = False\n",
    "y_train_fm, y_test_fm = _run_base_model_dfm(dfTrain, dfTest, folds, fm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DNN Model ------------------\n",
    "dnn_params = dfm_params.copy()\n",
    "dnn_params[\"use_fm\"] = False\n",
    "y_train_dnn, y_test_dnn = _run_base_model_dfm(dfTrain, dfTest, folds, dnn_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以下为修改版，支持多值特征\n",
    "# 多值特征格式为Xi = [1,2,3,4,[5,6,7]]\n",
    "## 其中[5，6，7]为多值特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n",
      "#params: 4891635\n",
      "split train to batch...\n",
      "Training begin...\n",
      "Train No.1 batch, size is  7918933...\n",
      "[1] train-result=0.7505, valid-result=0.7536 [1655.4 s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import config\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from DeepFM import DeepFM\n",
    "import random \n",
    "\n",
    "\n",
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 10,\n",
    "    \"dropout_fm\": [1.0, 1.0],\n",
    "    \"deep_layers\": [300, 300, 300],\n",
    "    \"dropout_deep\": [1, 1, 1, 1],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 1,\n",
    "    \"batch_size\": 4096,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"loss_type\": \"logloss\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    #\"eval_metric\": gini_norm,\n",
    "    \"random_seed\": config.RANDOM_SEED\n",
    "}\n",
    "\n",
    "\n",
    "has_cross = False\n",
    "valid_rate = 0.1\n",
    "\n",
    "print('loading data...')\n",
    "test1 = pd.read_csv('../../Tencent Data/test2.csv')\n",
    "res_test = test1[['aid','uid']]\n",
    "del test1\n",
    "Y_train = pd.read_csv('../../Tencent Data/label.csv')\n",
    "Y_train.loc[Y_train['label'] == -1,'label'] = 0\n",
    "Y_train = Y_train.values.reshape(-1,)\n",
    "\n",
    "data = pd.read_csv('../../Tencent Data/trans2.csv')\n",
    "data = data.astype('str')\n",
    "\n",
    "Test = data.iloc[8798814:]\n",
    "Train = data.iloc[:8798814].values\n",
    "del data\n",
    "\n",
    "\n",
    "\n",
    "if has_cross:\n",
    "    print('loading cross feat...')\n",
    "    cross_feat = pd.read_csv('../../Tencent Data/cross_feat.csv')\n",
    "    Xi_cross = None\n",
    "    F = True\n",
    "    row_num = len(cross_feat)\n",
    "    for i in range(419860,419908):\n",
    "        if F:\n",
    "            Xi_cross = np.array([str(i)]).repeat(row_num).reshape(-1,1)\n",
    "            F = False\n",
    "        else:\n",
    "            Xi_cross = np.hstack((Xi_cross,np.array([str(i)]).repeat(row_num).reshape(-1,1)))\n",
    "\n",
    "    Xv_cross = cross_feat.values\n",
    "\n",
    "    dfm_params[\"feature_size\"] = 419763+len(cross_feat.columns)\n",
    "    dfm_params[\"field_size\"] = 31+len(cross_feat.columns)\n",
    "    del cross_feat\n",
    "    \n",
    "    Xi_test = np.hstack((np.array(Test),Xi_cross[8798814:]))\n",
    "    del Test\n",
    "    Xv_test = np.hstack((np.ones([len(Xi_test),len(Xi_test[0])]),Xv_cross[8798814:]))\n",
    "    \n",
    "    Xv_train = np.hstack((np.ones([len(Train),len(Train[0])]),Xv_cross))\n",
    "    Xi_Train = np.hstack((Train,Xi_cross))\n",
    "else:\n",
    "    dfm_params[\"feature_size\"] = 419763\n",
    "    dfm_params[\"field_size\"] = 31\n",
    "    \n",
    "    Xi_test = np.array(Test)\n",
    "    del Test\n",
    "    Xv_test = np.ones([len(Xi_test),len(Xi_test[0])])\n",
    "    \n",
    "    Xv_train = np.ones([len(Train),len(Train[0])])\n",
    "    Xi_train = Train\n",
    "\n",
    "del Train\n",
    "\n",
    "train_size = len(Xi_train)\n",
    "chunksize = 7918933\n",
    "dfm = DeepFM(**dfm_params)\n",
    "\n",
    "valid_size = int(valid_rate * train_size)\n",
    "shuffle_index = range(train_size)\n",
    "random.shuffle(shuffle_index)\n",
    "\n",
    "train_index = shuffle_index[valid_size:]\n",
    "valid_index = shuffle_index[:valid_size]\n",
    "\n",
    "print('split train to batch...')\n",
    "batch_index = []\n",
    "for i in range(len(train_index) / chunksize):\n",
    "     batch_index.append(shuffle_index[i * chunksize:(i+1)*chunksize])\n",
    "if (len(train_index) % chunksize) != 0:\n",
    "    batch_index.append(shuffle_index[-(len(train_index) % chunksize):])\n",
    "\n",
    "gc.collect()    \n",
    "\n",
    "Xi_valid = Xi_train[valid_index]\n",
    "Xv_valid = Xv_train[valid_index]\n",
    "Y_valid = Y_train[valid_index]\n",
    "print('Training begin...')\n",
    "fff = open('output/log.txt','a')\n",
    "fff.write('begin\\n')\n",
    "fff.close()\n",
    "for i in range(len(batch_index)):\n",
    "    print('Train No.%d batch, size is  %d...'% (i+1, len(batch_index[i])))\n",
    "    xi_train = Xi_train[batch_index[i]]\n",
    "    xv_train = Xv_train[batch_index[i]]\n",
    "    y_train = Y_train[batch_index[i]].tolist()\n",
    "    dfm.fit(xi_train, xv_train, y_train, Xi_valid, Xv_valid, Y_valid)\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520056875776785\n"
     ]
    }
   ],
   "source": [
    "# predict the whole train set     \n",
    "pre = dfm.predict(Xi_train, Xv_train).tolist()\n",
    "auc = roc_auc_score(Y_train, pre)\n",
    "fff = open('output/log.txt','a')\n",
    "fff.write('all train set testing\\n')\n",
    "fff.write('auc %f\\ncomplete\\n' % auc)\n",
    "fff.close()\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Xi_train.tolist()\n",
    "a=[]\n",
    "for i in range(173):\n",
    "    a.append([])\n",
    "\n",
    "for each in b:\n",
    "    a[int(each[0])].append(b.index(each))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the test set and save the result to csv    \n",
    "res_test['score'] = dfm.predict(Xi_test, Xv_test)\n",
    "save_path = os.path.join(config.SUB_DIR, 'submission.csv')\n",
    "res_test.to_csv(save_path, index=False, float_format=\"%.6f\")\n",
    "os.system('zip %s.zip %s' % (save_path, save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model2/test2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm.saver.save(dfm.sess,'model2/test2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from DeepFM import DeepFM\n",
    "dfm_params = {\n",
    "    \"use_fm\": True,\n",
    "    \"use_deep\": True,\n",
    "    \"embedding_size\": 8,\n",
    "    \"dropout_fm\": [1.0, 1.0],\n",
    "    \"deep_layers\": [100, 100],\n",
    "    \"dropout_deep\": [0.9, 0.9, 0.9],\n",
    "    \"deep_layers_activation\": tf.nn.relu,\n",
    "    \"epoch\": 15,\n",
    "    \"batch_size\": 2048,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"optimizer_type\": \"adam\",\n",
    "    \"batch_norm\": 1,\n",
    "    \"batch_norm_decay\": 0.995,\n",
    "    \"l2_reg\": 0.01,\n",
    "    \"verbose\": True,\n",
    "    #\"eval_metric\": gini_norm,\n",
    "    \"random_seed\": 2018\n",
    "}\n",
    "\n",
    "\n",
    "dfm_params[\"feature_size\"] = 419859\n",
    "dfm_params[\"field_size\"] = 31\n",
    "dfm = DeepFM(**dfm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "a= [['1','2','3','1 2 3','1 2 3'],['1','2','3','1 2 3','1 2 3'],['1','2','3','1 2 3','1 2 3']]\n",
    "a=np.array(a).reshape(-1,)\n",
    "\n",
    "\n",
    "split_tags = tf.string_split(a, \" \")\n",
    "\n",
    "\n",
    "tags =  tf.SparseTensor(\n",
    "      indices=split_tags.indices,\n",
    "      values=tf.string_to_number(split_tags.values, out_type=tf.int64, name=None), ## 这里给出了不同值通过表查到的index ##\n",
    "      dense_shape=split_tags.dense_shape)\n",
    "\n",
    "TAG_EMBEDDING_DIM = 3\n",
    "embedding_params = tf.Variable(tf.truncated_normal([100, TAG_EMBEDDING_DIM]))\n",
    "\n",
    "\n",
    "embedded_tags = tf.nn.embedding_lookup_sparse(embedding_params, sp_ids=tags, sp_weights=None)\n",
    "embedded_tags = tf.reshape(embedded_tags,shape=[-1,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as s:\n",
    "  s.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  print(s.run([feat_index[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.random_uniform([100, 1], 0.0, 1.0), name=\"feature_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= [['1','2','3','1 2 3','1 2 3'],['1','2','3','1 2 3','1 2 3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_index = tf.convert_to_tensor(a)\n",
    "feat_index = tf.reshape(feat_index,shape=[1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
